{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MakerSpace Jam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary Dependencies and Context Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U -q openai==0.27.8 llama-index==0.8.6 nltk==3.8.1 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the OPENAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load token list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sheet_name = \"GSW_token_list\"\n",
    "workbook_id = '1MB1ZsQul4AB262AsaY4fHtGW4HWp2-56zB-E5xTbs2A'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{workbook_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = df['Token'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_string = '_'.join(token_list)\n",
    "token_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Trafilatura Web Reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install trafilatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of webpages to index\n",
    "webpages = [ \"https://www.basketball-reference.com/\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import TrafilaturaWebReader\n",
    "\n",
    "web_docs = TrafilaturaWebReader().load_data([webpages[0]])\n",
    "web_docs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser.simple import SimpleNodeParser\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=1000 ### YOUR CODE HERE\n",
    ")\n",
    "\n",
    "node_parser = SimpleNodeParser(\n",
    "    text_splitter=text_splitter ### YOUR CODE HERE\n",
    ")\n",
    "\n",
    "# parse nodes from workbooks and insert into vector index\n",
    "for w_doc in web_docs:\n",
    "    nodes = node_parser.get_nodes_from_documents([w_doc])\n",
    "    for node in nodes:\n",
    "        node.metadata = {'title': 'Basketball Stats and History',\n",
    "                         'type': 'webpage',\n",
    "                         'url': 'https://www.basketball-reference.com/',\n",
    "                         'description': 'Basketball Stats and History',\n",
    "                         'accessibility': 'public'\n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "from llama_index.schema import MetadataMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docEmailSample = Document(\n",
    "    text=\"Hey KD, let's grab dinner after the game on October 24th, Steph\", \n",
    "    metadata={\n",
    "        'doctype': 'email',\n",
    "        # 'datetime': \"2023-09-01T15:30:00Z\",\n",
    "        # 'email_from': 'kevin.durant@suns.nba',\n",
    "        # 'email_to': 'stephen.curry@warriors.nba',\n",
    "        # \"token_list\": token_string,\n",
    "        'from': 'Stephen Curry',\n",
    "        'to': 'Kevin Durant'\n",
    "    }\n",
    ")\n",
    "docEmailSample2 = Document(\n",
    "    text=\"Yo, you were a monster last year, can't wait to play against you in the opener! Draymond\", \n",
    "    metadata={\n",
    "        'doctype': 'email',\n",
    "        # 'datetime': \"2023-09-01T02:30:00Z\",\n",
    "        # 'email_from': 'lebron.james@lakers.nba',\n",
    "        # 'email_to': 'nikola.jokic@nuggets.nba',\n",
    "        # \"token_list\": token_string,\n",
    "        # 'team': 'Golden State Warriors',\n",
    "        'from': 'Draymond Green',\n",
    "        'to': 'Nikola Jokic'\n",
    "    }\n",
    ")\n",
    "docScheduleSample = Document(\n",
    "    text=\"\"\"\n",
    "        {\n",
    "            \"Date\": \"Tue Oct 24 2023\",\n",
    "            \"Start (ET)\": \"7:30p\",\n",
    "            \"Visitor/Neutral\": \"Golden State Warriors\",\n",
    "            \"PTS\": \"\",\n",
    "            \"Home/Neutral\": \"Denver Nuggets\",\n",
    "            \"PTS\": \"\",\n",
    "            \"Attend.\": \"\",\n",
    "            \"Arena\": \"Ball Arena\",\n",
    "            \"Notes\": \"\"\n",
    "        }\n",
    "    \"\"\",\n",
    "    metadata={\n",
    "        'doctype': 'schedule',\n",
    "        # \"token_list\": token_string,\n",
    "        'teams': 'Golden State Warriors' # idk how to get list of metadata\n",
    "    }\n",
    ")\n",
    "docScheduleSample2 = Document(\n",
    "    text=\"\"\"\n",
    "        {\n",
    "            \"Date\": \"Fri Oct 27 2023\",\n",
    "            \"Start (ET)\": \"10:00p\",\n",
    "            \"Visitor/Neutral\": \"Phoenix Suns\",\n",
    "            \"PTS\": \"\",\n",
    "            \"Home/Neutral\": \"Golden State Warriors\",\n",
    "            \"PTS\": \"\",\n",
    "            \"Attend.\": \"\",\n",
    "            \"Arena\": \"Chase Center\",\n",
    "            \"Notes\": \"\"\n",
    "        }\n",
    "    \"\"\",\n",
    "    metadata={\n",
    "        'doctype': 'schedule',     \n",
    "        # \"token_list\": token_string,\n",
    "        'team': 'Golden State Warriors' # idk how to get list of metadata\n",
    "############################ YOU ASK(??) FOR SMTH LIKE THIS:\n",
    "        # 'list': [\n",
    "        #     {'team': 'warriors'}, \n",
    "        #     {'team': 'lakers'},\n",
    "        #     {'team': 'nuggets'},\n",
    "        # ]\n",
    "    }\n",
    ")\n",
    "\n",
    "docAdditionalSamples = [docEmailSample, docEmailSample2, docScheduleSample, docScheduleSample2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example to play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docPano = Document(\n",
    "    text='NBA Player born Nov 1989 in Greece', \n",
    "    metadata={\n",
    "        'type': 'player', \n",
    "        'number': '42', \n",
    "        'team': 'surfers', \n",
    "        'position': 'floating point guard',\n",
    "        'specialty': 'eurostepping',\n",
    "        'dress-style': 'barefoot',\n",
    "        'secret': 'loves pizza'\n",
    "    }\n",
    ")\n",
    "docChristos = Document(\n",
    "    text='NBA Player born Dec 1994 in the USA', \n",
    "    metadata={\n",
    "        'type': 'player', \n",
    "        'number': '3', \n",
    "        'team': 'climbers', \n",
    "        'position': 'strong forward pass',\n",
    "        'specialty': 'ally-oop',\n",
    "        'dress-style': 'pink-on-Wednesdays',\n",
    "        'secret': 'loves cats, candy and cartoons'\n",
    "    },\n",
    "    excluded_llm_metadata_keys=['secret'],\n",
    "    metadata_seperator=\"::\",\n",
    "    metadata_template=\"{key}=>{value}\",\n",
    "    text_template=\"Metadata: {metadata_str}\\n-----\\nContent: {content}\",\n",
    ")\n",
    "\n",
    "docExamplesToPlayWith = [docPano, docChristos]\n",
    "\n",
    "print(\"The LLM sees this: \\n\", docChristos.get_content(metadata_mode=MetadataMode.LLM))\n",
    "print(\"The Embedding model sees this: \\n\", docChristos.get_content(metadata_mode=MetadataMode.EMBED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding()\n",
    "chunk_size = 1000\n",
    "llm = OpenAI(\n",
    "    temperature=0, \n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, \n",
    "    chunk_size=chunk_size,\n",
    "    embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is intended to be a global vector store to insert the nodes from all data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U -q chromadb==0.4.6 tiktoken==0.4.0 sentence-transformers==2.2.2 pydantic==1.10.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"all_data\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "vector_index = VectorStoreIndex([], storage_context=storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate Vector Store with Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse nodes for each loaded data source and insert it to the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_index.insert_nodes(nodes) \n",
    "# vector_index.insert_nodes(docExamplesToPlayWith)\n",
    "vector_index.insert_nodes(docAdditionalSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Metadata Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import FunctionTool\n",
    "from llama_index.vector_stores.types import (\n",
    "    VectorStoreInfo,\n",
    "    MetadataInfo,\n",
    "    ExactMatchFilter,\n",
    "    MetadataFilters,\n",
    ")\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "from typing import List, Tuple, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "info_emails_players = VectorStoreInfo(\n",
    "    content_info=\"emails exchanged between NBA players\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"from\",\n",
    "            type=\"str\",\n",
    "            description=\"\"\"\n",
    "email sent by a player of the Golden State Warriors, one of [Stephen Curry, \n",
    "Klay Thompson, \n",
    "Chris Paul, \n",
    "Andrew Wiggins,\n",
    "Draymond Green,\n",
    "Gary Payton II,\n",
    "Kevon Looney,\n",
    "Jonathan Kuminga,\n",
    "Moses Moody,\n",
    "Brandin Podziemski,\n",
    "Cory Joseph,\n",
    "Dario Šarić]\"\"\"\n",
    "        ), \n",
    "        MetadataInfo(\n",
    "            name=\"to\",\n",
    "            type=\"str\",\n",
    "            description=\"\"\"receiver of the email text, can be any NBA player\"\"\"\n",
    "        ), \n",
    "        MetadataInfo(\n",
    "            name='doctype',\n",
    "            type=\"str\",\n",
    "            description=\"email\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "info_schedule_team = VectorStoreInfo(\n",
    "    content_info=\"schedule of the Golden State Warriors games\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"team\",\n",
    "            type=\"str\",\n",
    "            description=\"Golden State Warriors\"\n",
    "        ), \n",
    "        MetadataInfo(\n",
    "            name='doctype',\n",
    "            type=\"str\",\n",
    "            description=\"schedule\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRetrieveModel(BaseModel):\n",
    "    query: str = Field(..., description=\"natural language query string\")\n",
    "    filter_key_list: List[str] = Field(\n",
    "        ..., description=\"List of metadata filter field names\"\n",
    "    )\n",
    "    filter_value_list: List[str] = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"List of metadata filter field values (corresponding to names specified in filter_key_list)\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = token_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_retrieve_fn(\n",
    "    query: str, filter_key_list: List[str], filter_value_list: List[str]\n",
    "):\n",
    "    \"\"\"Auto retrieval function.\n",
    "\n",
    "    Performs auto-retrieval from a vector database, and then applies a set of filters.\n",
    "\n",
    "    \"\"\"\n",
    "    query = query or \"Query\"\n",
    "    \n",
    "    # for i, (k, v) in enumerate(zip(filter_key_list, filter_value_list)):\n",
    "    #     if k == 'token_list':\n",
    "    #         if token not in v:\n",
    "    #             v = ''\n",
    "\n",
    "    exact_match_filters = [\n",
    "        ExactMatchFilter(key=k, value=v)\n",
    "        for k, v in zip(filter_key_list, filter_value_list)\n",
    "    ]\n",
    "    retriever = VectorIndexRetriever(\n",
    "        vector_index, filters=MetadataFilters(filters=exact_match_filters), top_k=top_k\n",
    "    )\n",
    "    # query_engine = vector_index.as_query_engine(filters=MetadataFilters(filters=exact_match_filters))\n",
    "    query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "\n",
    "    response = query_engine.query(query)\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_emails = f\"\"\"\\\n",
    "Use this tool to look up information about emails exchanged betweed players of the Golden State Warriors and any other NBA player.\n",
    "The vector database schema is given below:\n",
    "{info_emails_players.json()}\n",
    "\"\"\"\n",
    "auto_retrieve_tool_emails = FunctionTool.from_defaults(\n",
    "    fn=auto_retrieve_fn, \n",
    "    name='auto_retrieve_tool_emails',\n",
    "    description=description_emails, \n",
    "    fn_schema=AutoRetrieveModel\n",
    ")\n",
    "\n",
    "description_schedule = f\"\"\"\\\n",
    "Use this tool to look up the NBA game schedule of the Golden State Warriors.\n",
    "The vector database schema is given below:\n",
    "{info_schedule_team.json()}\n",
    "\"\"\"\n",
    "auto_retrieve_tool_schedule = FunctionTool.from_defaults(\n",
    "    fn=auto_retrieve_fn, \n",
    "    name='auto_retrieve_tool_schedule',\n",
    "    description=description_schedule, \n",
    "    fn_schema=AutoRetrieveModel\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL NBA Query Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q -U pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_df_from_workbook(sheet_name,\n",
    "                         workbook_id = '1MB1ZsQul4AB262AsaY4fHtGW4HWp2-56zB-E5xTbs2A'):\n",
    "    url = f'https://docs.google.com/spreadsheets/d/{workbook_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "    return pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names = ['Teams', 'Players', 'Schedule', 'Player_Stats']\n",
    "dict_of_dfs = {sheet: get_df_from_workbook(sheet) for sheet in sheet_names}\n",
    "dict_of_dfs['Teams'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite+pysqlite:///:memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict in dict_of_dfs:\n",
    "    print(dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_dfs['Teams'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dict_of_dfs:\n",
    "    dict_of_dfs[df].to_sql(df, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SQLDatabase\n",
    "\n",
    "sql_database = SQLDatabase(\n",
    "    engine,\n",
    "    # include_tables=['Teams', 'Players_2023-24', 'Schedule_2023-24', 'Player_Stats_2022-23_(Playoffs)', 'Player_Stats_2022-23_(Regular_Season)']\n",
    "    include_tables=list(dict_of_dfs.keys())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\n",
    "\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=list(dict_of_dfs.keys())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.query_engine import QueryEngineTool\n",
    "\n",
    "sql_nba_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine, # \n",
    "    name='sql_nba_tool', \n",
    "    description=(\"\"\"Useful for translating a natural language query into a SQL query over tables containing:\n",
    "                    1. teams, containing information related to all NBA teams\n",
    "                    2. players, containing information related to all NBA players\n",
    "                    3. schedule, containing information related to the entire NBA game schedule\n",
    "                    4. player_stats_playoffs, containing information related to all NBA player stats\n",
    "                    \"\"\"\n",
    "    ),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [sql_nba_tool, \n",
    "     auto_retrieve_tool_emails,\n",
    "     auto_retrieve_tool_schedule], \n",
    "    llm=llm, verbose=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"I am Stephen Curry. Do I have an email from Kevin Durant?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL GSW Query Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names = ['GSW_Team_Roster', 'GSW_Players_Summary', 'GSW_staff_and_executives']\n",
    "dict_of_dfs = {sheet: get_df_from_workbook(sheet) for sheet in sheet_names}\n",
    "dict_of_dfs['GSW_Team_Roster'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
