{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MakerSpace Jam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary Dependencies and Context Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U -q openai==0.27.8 llama-index==0.8.6 nltk==3.8.1 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the OPENAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load token list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sheet_name = \"GSW_token_list\"\n",
    "workbook_id = '1MB1ZsQul4AB262AsaY4fHtGW4HWp2-56zB-E5xTbs2A'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{workbook_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = df['Token'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_string = '_'.join(token_list)\n",
    "token_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Trafilatura Web Reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install trafilatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of webpages to index\n",
    "webpages = [ \"https://www.basketball-reference.com/\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import TrafilaturaWebReader\n",
    "\n",
    "web_docs = TrafilaturaWebReader().load_data([webpages[0]])\n",
    "web_docs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser.simple import SimpleNodeParser\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=1000 ### YOUR CODE HERE\n",
    ")\n",
    "\n",
    "node_parser = SimpleNodeParser(\n",
    "    text_splitter=text_splitter ### YOUR CODE HERE\n",
    ")\n",
    "\n",
    "# parse nodes from workbooks and insert into vector index\n",
    "for w_doc in web_docs:\n",
    "    nodes = node_parser.get_nodes_from_documents([w_doc])\n",
    "    for node in nodes:\n",
    "        node.metadata = {'title': 'Basketball Stats and History',\n",
    "                         'type': 'webpage',\n",
    "                         'url': 'https://www.basketball-reference.com/',\n",
    "                         'description': 'Basketball Stats and History',\n",
    "                         'accessibility': 'public'\n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "from llama_index.schema import MetadataMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "docEmailSample = Document(\n",
    "    text=\"Hey KD, let's grab dinner after the game on October 24th, Steph\", \n",
    "    metadata={\n",
    "        'from_to': 'Stephen Curry / Kevin Durant',\n",
    "        # 'datetime': \"2023-09-01T15:30:00Z\",\n",
    "        # 'email_from': 'kevin.durant@suns.nba',\n",
    "        # 'email_to': 'stephen.curry@warriors.nba',\n",
    "        # \"token_list\": token_string,\n",
    "        # 'from': 'Stephen Curry',\n",
    "        # 'to': 'Kevin Durant'\n",
    "    }\n",
    ")\n",
    "docEmailSample2 = Document(\n",
    "    text=\"Yo Joker, you were a monster last year, can't wait to play against you in the opener! Draymond\", \n",
    "    metadata={\n",
    "        'from_to': 'Draymond Green / Nikola Jokic',\n",
    "        # 'datetime': \"2023-09-01T02:30:00Z\",\n",
    "        # 'email_from': 'lebron.james@lakers.nba',\n",
    "        # 'email_to': 'nikola.jokic@nuggets.nba',\n",
    "        # \"token_list\": token_string,\n",
    "        # 'team': 'Golden State Warriors',\n",
    "        # 'from': 'Draymond Green',\n",
    "        # 'to': 'Nikola Jokic'\n",
    "    }\n",
    ")\n",
    "docScheduleSample = Document(\n",
    "    text=\"\"\"\n",
    "        {\n",
    "            \"Date\": \"Tue Oct 24 2023\",\n",
    "            \"Start (ET)\": \"7:30p\",\n",
    "            \"Visitor/Neutral\": \"Golden State Warriors\",\n",
    "            \"PTS\": \"\",\n",
    "            \"Home/Neutral\": \"Denver Nuggets\",\n",
    "            \"PTS\": \"\",\n",
    "            \"Attend.\": \"\",\n",
    "            \"Arena\": \"Ball Arena\",\n",
    "            \"Notes\": \"\"\n",
    "        }\n",
    "    \"\"\",\n",
    "    metadata={\n",
    "        'team': 'Golden State Warriors',\n",
    "        # \"token_list\": token_string,\n",
    "        # 'teams': 'Golden State Warriors' # idk how to get list of metadata\n",
    "    }\n",
    ")\n",
    "docScheduleSample2 = Document(\n",
    "    text=\"\"\"\n",
    "        {\n",
    "            \"Date\": \"Fri Oct 27 2023\",\n",
    "            \"Start (ET)\": \"10:00p\",\n",
    "            \"Visitor/Neutral\": \"Phoenix Suns\",\n",
    "            \"PTS\": \"\",\n",
    "            \"Home/Neutral\": \"Golden State Warriors\",\n",
    "            \"PTS\": \"\",\n",
    "            \"Attend.\": \"\",\n",
    "            \"Arena\": \"Chase Center\",\n",
    "            \"Notes\": \"\"\n",
    "        }\n",
    "    \"\"\",\n",
    "    metadata={\n",
    "        'team': 'Golden State Warriors',     \n",
    "        # \"token_list\": token_string,\n",
    "        # 'team': 'Golden State Warriors' # idk how to get list of metadata\n",
    "############################ YOU ASK(??) FOR SMTH LIKE THIS:\n",
    "        # 'list': [\n",
    "        #     {'team': 'warriors'}, \n",
    "        #     {'team': 'lakers'},\n",
    "        #     {'team': 'nuggets'},\n",
    "        # ]\n",
    "    }\n",
    ")\n",
    "\n",
    "docAdditionalSamples = [docEmailSample, docEmailSample2, docScheduleSample, docScheduleSample2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding()\n",
    "chunk_size = 1000\n",
    "llm = OpenAI(\n",
    "    temperature=0, \n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, \n",
    "    chunk_size=chunk_size,\n",
    "    embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is intended to be a global vector store to insert the nodes from all data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U -q chromadb==0.4.6 tiktoken==0.4.0 sentence-transformers==2.2.2 pydantic==1.10.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.posthog:Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
      "Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "# chroma_collection = chroma_client.create_collection(\"all_data\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "vector_index = VectorStoreIndex([], storage_context=storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate Vector Store with Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse nodes for each loaded data source and insert it to the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_index.insert_nodes(nodes) \n",
    "# vector_index.insert_nodes(docExamplesToPlayWith)\n",
    "vector_index.insert_nodes(docAdditionalSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Metadata Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import FunctionTool\n",
    "from llama_index.vector_stores.types import (\n",
    "    VectorStoreInfo,\n",
    "    MetadataInfo,\n",
    "    ExactMatchFilter,\n",
    "    MetadataFilters,\n",
    ")\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "from typing import List, Tuple, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "info_emails_players = VectorStoreInfo(\n",
    "    content_info=\"emails exchanged between NBA players\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"from_to\",\n",
    "            type=\"str\",\n",
    "            description=\"\"\"\n",
    "email sent by a player of the Golden State Warriors to any other NBA player, one of [\n",
    "Stephen Curry / any NBA player, \n",
    "Klay Thompson / any NBA player, \n",
    "Chris Paul / any NBA player, \n",
    "Andrew Wiggins / any NBA player, \n",
    "Draymond Green / any NBA player, \n",
    "Gary Payton II / any NBA player, \n",
    "Kevon Looney / any NBA player, \n",
    "Jonathan Kuminga / any NBA player, \n",
    "Moses Moody / any NBA player, \n",
    "Brandin Podziemski / any NBA player, \n",
    "Cory Joseph / any NBA player, \n",
    "Dario Šarić / any NBA player]\"\"\"\n",
    "        ), \n",
    "        # MetadataInfo(\n",
    "        #     name=\"to\",\n",
    "        #     type=\"str\",\n",
    "        #     description=\"\"\"receiver of the email text, can be any NBA player\"\"\"\n",
    "        # ), \n",
    "        # MetadataInfo(\n",
    "        #     name='doctype',\n",
    "        #     type=\"str\",\n",
    "        #     description=\"email\"\n",
    "        # )\n",
    "    ]\n",
    ")\n",
    "info_schedule_team = VectorStoreInfo(\n",
    "    content_info=\"schedule of the Golden State Warriors games\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"team\",\n",
    "            type=\"str\",\n",
    "            description=\"Golden State Warriors\"\n",
    "        ), \n",
    "        # MetadataInfo(\n",
    "        #     name='doctype',\n",
    "        #     type=\"str\",\n",
    "        #     description=\"schedule\"\n",
    "        # )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRetrieveModel(BaseModel):\n",
    "    query: str = Field(..., description=\"natural language query string\")\n",
    "    filter_key_list: List[str] = Field(\n",
    "        ..., description=\"List of metadata filter field names\"\n",
    "    )\n",
    "    filter_value_list: List[str] = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"List of metadata filter field values (corresponding to names specified in filter_key_list)\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_retrieve_fn(\n",
    "    query: str, filter_key_list: List[str], filter_value_list: List[str]\n",
    "):\n",
    "    \"\"\"Auto retrieval function.\n",
    "\n",
    "    Performs auto-retrieval from a vector database, and then applies a set of filters.\n",
    "\n",
    "    \"\"\"\n",
    "    query = query or \"Query\"\n",
    "    \n",
    "    # for i, (k, v) in enumerate(zip(filter_key_list, filter_value_list)):\n",
    "    #     if k == 'token_list':\n",
    "    #         if token not in v:\n",
    "    #             v = ''\n",
    "\n",
    "    exact_match_filters = [\n",
    "        ExactMatchFilter(key=k, value=v)\n",
    "        for k, v in zip(filter_key_list, filter_value_list)\n",
    "    ]\n",
    "    retriever = VectorIndexRetriever(\n",
    "        vector_index, filters=MetadataFilters(filters=exact_match_filters), top_k=top_k\n",
    "    )\n",
    "    # query_engine = vector_index.as_query_engine(filters=MetadataFilters(filters=exact_match_filters))\n",
    "    query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "\n",
    "    response = query_engine.query(query)\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_emails = f\"\"\"\\\n",
    "Use this tool to look up information about emails exchanged betweed players of the Golden State Warriors and any other NBA player.\n",
    "The vector database schema is given below:\n",
    "{info_emails_players.json()}\n",
    "\"\"\"\n",
    "auto_retrieve_tool_emails = FunctionTool.from_defaults(\n",
    "    fn=auto_retrieve_fn, \n",
    "    name='auto_retrieve_tool_emails',\n",
    "    description=description_emails, \n",
    "    fn_schema=AutoRetrieveModel\n",
    ")\n",
    "\n",
    "description_schedule = f\"\"\"\\\n",
    "Use this tool to look up the NBA game schedule of the Golden State Warriors.\n",
    "The vector database schema is given below:\n",
    "{info_schedule_team.json()}\n",
    "\"\"\"\n",
    "auto_retrieve_tool_schedule = FunctionTool.from_defaults(\n",
    "    fn=auto_retrieve_fn, \n",
    "    name='auto_retrieve_tool_schedule',\n",
    "    description=description_schedule, \n",
    "    fn_schema=AutoRetrieveModel\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL NBA Query Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q -U pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_df_from_workbook(sheet_name,\n",
    "                         workbook_id = '1MB1ZsQul4AB262AsaY4fHtGW4HWp2-56zB-E5xTbs2A'):\n",
    "    url = f'https://docs.google.com/spreadsheets/d/{workbook_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "    return pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names = ['Teams', 'Players', 'Schedule', 'Player_Stats']\n",
    "dict_of_dfs = {sheet: get_df_from_workbook(sheet) for sheet in sheet_names}\n",
    "dict_of_dfs['Teams'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite+pysqlite:///:memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict in dict_of_dfs:\n",
    "    print(dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_dfs['Teams'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dict_of_dfs:\n",
    "    dict_of_dfs[df].to_sql(df, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SQLDatabase\n",
    "\n",
    "sql_database = SQLDatabase(\n",
    "    engine,\n",
    "    # include_tables=['Teams', 'Players_2023-24', 'Schedule_2023-24', 'Player_Stats_2022-23_(Playoffs)', 'Player_Stats_2022-23_(Regular_Season)']\n",
    "    include_tables=list(dict_of_dfs.keys())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\n",
    "\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=list(dict_of_dfs.keys())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.query_engine import QueryEngineTool\n",
    "\n",
    "sql_nba_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine, # \n",
    "    name='sql_nba_tool', \n",
    "    description=(\"\"\"Useful for translating a natural language query into a SQL query over tables containing:\n",
    "                    1. teams, containing information related to all NBA teams\n",
    "                    2. players, containing information related to all NBA players and the teams they play for\n",
    "                    3. schedule, containing information related to the entire NBA game schedule\n",
    "                    4. player_stats_playoffs, containing information related to all NBA player stats\n",
    "                    \"\"\"\n",
    "    ),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [sql_nba_tool, \n",
    "     auto_retrieve_tool_emails,\n",
    "     auto_retrieve_tool_schedule], \n",
    "    llm=llm, verbose=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: auto_retrieve_tool_emails with args: {\n",
      "  \"query\": \"Stephen Curry / Kevin Durant\",\n",
      "  \"filter_key_list\": [\"from_to\"],\n",
      "  \"filter_value_list\": [\"Stephen Curry / Kevin Durant\"]\n",
      "}\n",
      "Got output: Stephen Curry is suggesting to Kevin Durant that they grab dinner after the game on October 24th.\n",
      "========================\n",
      "=== Calling Function ===\n",
      "Calling function: auto_retrieve_tool_schedule with args: {\n",
      "  \"query\": \"Golden State Warriors\"\n",
      "}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "auto_retrieve_fn() missing 2 required positional arguments: 'filter_key_list' and 'filter_value_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mchat(\u001b[39m\"\u001b[39m\u001b[39mI am Stephen Curry. Do I have an email from Kevin Durant? When are we playing against his team\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.11/site-packages/llama_index/callbacks/utils.py:38\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m callback_manager \u001b[39m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[1;32m     37\u001b[0m \u001b[39mwith\u001b[39;00m callback_manager\u001b[39m.\u001b[39mas_trace(trace_id):\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.11/site-packages/llama_index/agent/openai_agent.py:305\u001b[0m, in \u001b[0;36mBaseOpenAIAgent.chat\u001b[0;34m(self, message, chat_history, function_call)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39m@trace_method\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mchat\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchat\u001b[39m(\n\u001b[1;32m    300\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m     function_call: Union[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    304\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AgentChatResponse:\n\u001b[0;32m--> 305\u001b[0m     chat_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chat(\n\u001b[1;32m    306\u001b[0m         message, chat_history, function_call, mode\u001b[39m=\u001b[39mChatResponseMode\u001b[39m.\u001b[39mWAIT\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(chat_response, AgentChatResponse)\n\u001b[1;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m chat_response\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.11/site-packages/llama_index/agent/openai_agent.py:269\u001b[0m, in \u001b[0;36mBaseOpenAIAgent._chat\u001b[0;34m(self, message, chat_history, function_call, mode)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_function_call, \u001b[39mdict\u001b[39m)\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_function(tools, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_function_call)\n\u001b[1;32m    270\u001b[0m     n_function_calls \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    272\u001b[0m \u001b[39mreturn\u001b[39;00m agent_chat_response\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.11/site-packages/llama_index/agent/openai_agent.py:206\u001b[0m, in \u001b[0;36mBaseOpenAIAgent._call_function\u001b[0;34m(self, tools, function_call)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_function\u001b[39m(\u001b[39mself\u001b[39m, tools: List[BaseTool], function_call: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     function_message, tool_output \u001b[39m=\u001b[39m call_function(\n\u001b[1;32m    207\u001b[0m         tools, function_call, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msources\u001b[39m.\u001b[39mappend(tool_output)\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mput(function_message)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.11/site-packages/llama_index/agent/openai_agent.py:50\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(tools, function_call, verbose)\u001b[0m\n\u001b[1;32m     48\u001b[0m tool \u001b[39m=\u001b[39m get_function_by_name(tools, name)\n\u001b[1;32m     49\u001b[0m argument_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(arguments_str)\n\u001b[0;32m---> 50\u001b[0m output \u001b[39m=\u001b[39m tool(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39margument_dict)\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m     52\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot output: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(output)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.11/site-packages/llama_index/tools/types.py:124\u001b[0m, in \u001b[0;36mAsyncBaseTool.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ToolOutput:\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.11/site-packages/llama_index/tools/function_tool.py:77\u001b[0m, in \u001b[0;36mFunctionTool.call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ToolOutput:\n\u001b[1;32m     76\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     tool_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m ToolOutput(\n\u001b[1;32m     79\u001b[0m         content\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(tool_output),\n\u001b[1;32m     80\u001b[0m         tool_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mname,\n\u001b[1;32m     81\u001b[0m         raw_input\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m: args, \u001b[39m\"\u001b[39m\u001b[39mkwargs\u001b[39m\u001b[39m\"\u001b[39m: kwargs},\n\u001b[1;32m     82\u001b[0m         raw_output\u001b[39m=\u001b[39mtool_output,\n\u001b[1;32m     83\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: auto_retrieve_fn() missing 2 required positional arguments: 'filter_key_list' and 'filter_value_list'"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"I am Stephen Curry. Do I have an email from Kevin Durant? When are we playing against his team?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL GSW Query Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names = ['GSW_Team_Roster', 'GSW_Players_Summary', 'GSW_staff_and_executives']\n",
    "dict_of_dfs = {sheet: get_df_from_workbook(sheet) for sheet in sheet_names}\n",
    "dict_of_dfs['GSW_Team_Roster'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
