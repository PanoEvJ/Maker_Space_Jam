{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MakerSpace Jam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary Dependencies and Context Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U -q openai==0.27.8 llama-index==0.8.6 nltk==3.8.1 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the OPENAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.node_parser.simple import SimpleNodeParser\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding()\n",
    "chunk_size = 1000\n",
    "llm = OpenAI(\n",
    "    temperature=0, \n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, \n",
    "    chunk_size=chunk_size,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=chunk_size\n",
    ")\n",
    "\n",
    "node_parser = SimpleNodeParser(\n",
    "    text_splitter=text_splitter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U -q wikipedia  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of wikipedia pages to index\n",
    "webpages = [ \"https://www.basketball-reference.com/\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple Web Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index import SimpleWebPageReader, TrafilaturaWebReader\n",
    "\n",
    "# web_docs = SimpleWebPageReader(html_to_text=True).load_data([webpages[0]])\n",
    "# web_docs[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trafilatura Web Reader (seems better!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trafilatura in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: certifi in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from trafilatura) (2023.5.7)\n",
      "Requirement already satisfied: courlan>=0.9.3 in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from trafilatura) (0.9.3)\n",
      "Requirement already satisfied: htmldate>=1.4.3 in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from trafilatura) (1.5.0)\n",
      "Requirement already satisfied: justext>=3.0.0 in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from trafilatura) (3.0.0)\n",
      "Requirement already satisfied: lxml>=4.9.2 in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from trafilatura) (4.9.3)\n",
      "Requirement already satisfied: charset-normalizer>=3.1.0 in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from trafilatura) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from trafilatura) (1.26.15)\n",
      "Requirement already satisfied: langcodes>=3.3.0 in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from courlan>=0.9.3->trafilatura) (3.3.0)\n",
      "Requirement already satisfied: tld>=0.13 in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from courlan>=0.9.3->trafilatura) (0.13)\n",
      "Requirement already satisfied: dateparser>=1.1.2 in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from htmldate>=1.4.3->trafilatura) (1.1.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from htmldate>=1.4.3->trafilatura) (2.8.2)\n",
      "Requirement already satisfied: pytz in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from dateparser>=1.1.2->htmldate>=1.4.3->trafilatura) (2023.3)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from dateparser>=1.1.2->htmldate>=1.4.3->trafilatura) (2023.5.5)\n",
      "Requirement already satisfied: tzlocal in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from dateparser>=1.1.2->htmldate>=1.4.3->trafilatura) (4.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from python-dateutil>=2.8.2->htmldate>=1.4.3->trafilatura) (1.16.0)\n",
      "Requirement already satisfied: pytz-deprecation-shim in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from tzlocal->dateparser>=1.1.2->htmldate>=1.4.3->trafilatura) (0.1.0.post0)\n",
      "Requirement already satisfied: tzdata in /home/pevj/anaconda3/envs/llm/lib/python3.11/site-packages (from pytz-deprecation-shim->tzlocal->dateparser>=1.1.2->htmldate>=1.4.3->trafilatura) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install trafilatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:trafilatura.downloads:download error: https://www.basketball-reference.com/ HTTPSConnectionPool(host='www.basketball-reference.com', port=443): Max retries exceeded with url: / (Caused by ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')))\n",
      "download error: https://www.basketball-reference.com/ HTTPSConnectionPool(host='www.basketball-reference.com', port=443): Max retries exceeded with url: / (Caused by ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')))\n",
      "download error: https://www.basketball-reference.com/ HTTPSConnectionPool(host='www.basketball-reference.com', port=443): Max retries exceeded with url: / (Caused by ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m \u001b[39mimport\u001b[39;00m TrafilaturaWebReader\n\u001b[1;32m      3\u001b[0m web_docs \u001b[39m=\u001b[39m TrafilaturaWebReader()\u001b[39m.\u001b[39mload_data([webpages[\u001b[39m0\u001b[39m]])\n\u001b[0;32m----> 4\u001b[0m web_docs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from llama_index import TrafilaturaWebReader\n",
    "\n",
    "web_docs = TrafilaturaWebReader().load_data([webpages[0]])\n",
    "web_docs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is intended to be a global vector store to insert the nodes from all data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U -q chromadb==0.4.6 tiktoken==0.4.0 sentence-transformers==2.2.2 pydantic==1.10.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"all_data\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "vector_index = VectorStoreIndex([], storage_context=storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct & Insert Nodes to Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse nodes for each loaded data source and insert it to the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse nodes from web docs and insert into vector index\n",
    "for w_doc in web_docs:\n",
    "    # print(wiki_doc)\n",
    "    nodes = node_parser.get_nodes_from_documents([w_doc])\n",
    "    for node in nodes:\n",
    "        node.metadata = {'title': 'Basketball Stats and History'}\n",
    "    vector_index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Metadata Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create our `VectoreStoreInfo` object which will hold all the relevant metadata we need for each component (in this case title metadata).\n",
    "\n",
    "Notice that you need to include it in a text list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import FunctionTool\n",
    "from llama_index.vector_stores.types import (\n",
    "    VectorStoreInfo,\n",
    "    MetadataInfo,\n",
    "    ExactMatchFilter,\n",
    "    MetadataFilters,\n",
    ")\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "from typing import List, Tuple, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"information about NBA players, teams, games, organizations, etc.\",\n",
    "    metadata_info=[MetadataInfo(\n",
    "        name=\"title\",\n",
    "        type=\"str\",\n",
    "        description=\"info of player, team, organization, games, etc.\",\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our base PyDantic object that we can use to ensure compatability with our application layer. This verifies that the response from the OpenAI endpoint conforms to this schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRetrieveModel(BaseModel):\n",
    "    query: str = Field(..., description=\"natural language query string\")\n",
    "    filter_key_list: List[str] = Field(\n",
    "        ..., description=\"List of metadata filter field names\"\n",
    "    )\n",
    "    filter_value_list: List[str] = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"List of metadata filter field values (corresponding to names specified in filter_key_list)\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build our function that we will use to query the functional endpoint.\n",
    "\n",
    ">The `docstring` is important to the functionality of the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_retrieve_fn(\n",
    "    query: str, filter_key_list: List[str], filter_value_list: List[str]\n",
    "):\n",
    "    \"\"\"Auto retrieval function.\n",
    "\n",
    "    Performs auto-retrieval from a vector database, and then applies a set of filters.\n",
    "\n",
    "    \"\"\"\n",
    "    query = query or \"Query\"\n",
    "\n",
    "    exact_match_filters = [\n",
    "        ExactMatchFilter(key=k, value=v)\n",
    "        for k, v in zip(filter_key_list, filter_value_list)\n",
    "    ]\n",
    "    retriever = VectorIndexRetriever(\n",
    "        vector_index, filters=MetadataFilters(filters=exact_match_filters), top_k=top_k\n",
    "    )\n",
    "    query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "\n",
    "    response = query_engine.query(query)\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to wrap our system in a tool in order to integrate it into the larger application.\n",
    "\n",
    "Source Code Here:\n",
    "- [`FunctionTool`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/tools/function_tool.py#L21)\n",
    "\n",
    "Extra stuff about fintering:\n",
    "- [ExactMatchFilter](https://gpt-index.readthedocs.io/en/latest/api_reference/query/retrievers/vector_store.html#llama_index.vector_stores.types.ExactMatchFilter)\n",
    "- [VectorStoreInfo](https://gpt-index.readthedocs.io/en/latest/api_reference/query/retrievers/vector_store.html#llama_index.vector_stores.types.VectorStoreInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = f\"\"\"\\\n",
    "Use this tool to look up semantic information about NBA.\n",
    "The vector database schema is given below:\n",
    "{vector_store_info.json()}\n",
    "\"\"\"\n",
    "\n",
    "auto_retrieve_tool = FunctionTool.from_defaults(\n",
    "    fn=auto_retrieve_fn, \n",
    "    name='auto_retrieve_tool',\n",
    "    description=description, \n",
    "    fn_schema=AutoRetrieveModel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that's left to do is attach the tool to an OpenAIAgent and let it rip!\n",
    "\n",
    "Source Code Here:\n",
    "- [`OpenAIAgent`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/agent/openai_agent.py#L361)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [auto_retrieve_tool], llm=llm, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"Who is the current 'Trending Player' in the NBA?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL retriever tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q -U sqlalchemy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_workbook(sheet_name,\n",
    "                         workbook_id = '1MB1ZsQul4AB262AsaY4fHtGW4HWp2-56zB-E5xTbs2A'):\n",
    "    url = f'https://docs.google.com/spreadsheets/d/{workbook_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "    return pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Franchise</th>\n",
       "      <th>Lg</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Yrs</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W/L%</th>\n",
       "      <th>Plyfs</th>\n",
       "      <th>Div</th>\n",
       "      <th>Conf</th>\n",
       "      <th>Champ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>NBA</td>\n",
       "      <td>1949-50</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>75</td>\n",
       "      <td>5855</td>\n",
       "      <td>2891</td>\n",
       "      <td>2964</td>\n",
       "      <td>0.494</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>NBA/BAA</td>\n",
       "      <td>1946-47</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>78</td>\n",
       "      <td>6032</td>\n",
       "      <td>3570</td>\n",
       "      <td>2462</td>\n",
       "      <td>0.592</td>\n",
       "      <td>60</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brooklyn Nets</td>\n",
       "      <td>NBA/ABA</td>\n",
       "      <td>1967-68</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>57</td>\n",
       "      <td>4530</td>\n",
       "      <td>1996</td>\n",
       "      <td>2534</td>\n",
       "      <td>0.441</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charlotte Hornets</td>\n",
       "      <td>NBA</td>\n",
       "      <td>1988-89</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>34</td>\n",
       "      <td>2631</td>\n",
       "      <td>1153</td>\n",
       "      <td>1478</td>\n",
       "      <td>0.438</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>NBA</td>\n",
       "      <td>1966-67</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>58</td>\n",
       "      <td>4598</td>\n",
       "      <td>2344</td>\n",
       "      <td>2254</td>\n",
       "      <td>0.510</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Franchise       Lg     From       To  Yrs     G     W     L   W/L%  \\\n",
       "0      Atlanta Hawks      NBA  1949-50  2023-24   75  5855  2891  2964  0.494   \n",
       "1     Boston Celtics  NBA/BAA  1946-47  2023-24   78  6032  3570  2462  0.592   \n",
       "2      Brooklyn Nets  NBA/ABA  1967-68  2023-24   57  4530  1996  2534  0.441   \n",
       "3  Charlotte Hornets      NBA  1988-89  2023-24   34  2631  1153  1478  0.438   \n",
       "4      Chicago Bulls      NBA  1966-67  2023-24   58  4598  2344  2254  0.510   \n",
       "\n",
       "   Plyfs  Div  Conf  Champ  \n",
       "0     49   12     0      1  \n",
       "1     60   33    10     17  \n",
       "2     31    5     2      2  \n",
       "3     10    0     0      0  \n",
       "4     37    9     6      6  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_df = get_df_from_workbook('Teams')\n",
    "teams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names = ['Teams']\n",
    "for sheet in sheet_names:\n",
    "    df = get_df_from_workbook(sheet)\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
